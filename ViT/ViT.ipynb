{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets,transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef clone_module_list(module: M, n: int) -> TypedModuleList[M]:\\n    \"\"\"\\n    ## Clone Module\\n\\n    Make a `nn.ModuleList` with clones of a given module\\n    \"\"\"\\n    return TypedModuleList([copy.deepcopy(module) for _ in range(n)])\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def clone_module_list(module: M, n: int) -> TypedModuleList[M]:\n",
    "    \"\"\"\n",
    "    ## Clone Module\n",
    "\n",
    "    Make a `nn.ModuleList` with clones of a given module\n",
    "    \"\"\"\n",
    "    return TypedModuleList([copy.deepcopy(module) for _ in range(n)])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(self, batch_size, num_classes, dim, depth, heads, mlp_dim, img_dim = [3,224,224], patch_dim = [3,56,56], dim_head = 64):\n",
    "        super().__init__()\n",
    "        image_h = img_dim[1]\n",
    "        image_w = img_dim[2]\n",
    "        patch_h = patch_dim[1]\n",
    "        patch_w = patch_dim[2]\n",
    "\n",
    "        n_patches = (image_h // patch_h) * (image_w // patch_w)\n",
    "        patch_dim = img_dim[0] * patch_h * patch_w\n",
    "\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            nn.Unfold(kernel_size=(patch_h, patch_w), stride=(patch_h, patch_w))\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = self.to_patch_embedding(img)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VisionTransformer(batch_size=32, num_classes=10, dim=64, depth=8, heads=64, mlp_dim=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn([16,3,224,224])    #(b,c,h,w)\n",
    "y = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 224, 224])\n",
      "torch.Size([16, 9408, 16])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
